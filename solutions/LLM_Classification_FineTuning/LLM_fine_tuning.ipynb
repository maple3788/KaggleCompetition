{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## This is from https://www.kaggle.com/code/arabidopsisthalian/fine-tune",
   "id": "ed519f247d8c9e82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T02:45:30.320245Z",
     "start_time": "2025-08-14T02:45:30.313852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import random\n",
    "from time import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification\n",
    "from peft import get_peft_model, PeftModel, PeftConfig, get_peft_config, LoraConfig, TaskType\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "881afa0f0c8fa075",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T02:54:27.624355Z",
     "start_time": "2025-08-14T02:54:27.619276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CFG:\n",
    "    NUM_EPOCH = 1\n",
    "    BATCH_SIZE = 16\n",
    "    DROPOUT = 0.05\n",
    "    MODEL_NAME = 'meta-llama/Meta-Llama-3-8B'\n",
    "    # MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-hf/1'\n",
    "    SEED = 2024\n",
    "    MAX_LENGTH = 1024\n",
    "    NUM_WARMUP_STEPS = 128\n",
    "    LR_MAX = 5e-5\n",
    "    NUM_LABELS = 3\n",
    "    LORA_RANK = 16\n",
    "    LORA_ALPHA = 32\n",
    "    LORA_MODULES = ['q_proj', 'v_proj']\n",
    "\n",
    "\n",
    "device = \"cpu\""
   ],
   "id": "726609d4d3896c21",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T02:45:34.611540Z",
     "start_time": "2025-08-14T02:45:34.602934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seeds(seed):\n",
    "    \"\"\"Set seeds for reproducibility\"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ],
   "id": "d0d2c1aee0ccd912",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T02:54:33.340394Z",
     "start_time": "2025-08-14T02:54:29.240052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.add_eos_token = True\n",
    "\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ],
   "id": "46f54ed40adb654c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T02:56:53.307936Z",
     "start_time": "2025-08-14T02:56:53.303219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_token_lengths(texts):\n",
    "    # tokenize and receive input_ids for reach text\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # return length of inputs_ids for each text\n",
    "    return [len(t) for t in input_ids]"
   ],
   "id": "b632863c8525aa7d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:08:40.240318Z",
     "start_time": "2025-08-14T03:08:38.765833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train: pd.DataFrame = pd.read_csv('../../kaggle/LLM_Classification_FineTuning/train.csv')\n",
    "\n",
    "\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # safer than train['prompt'] = ...\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "# Drop 'Nul' for training\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
    "train.drop(indexes, inplace=True)\n",
    "train.reset_index(inplace=True, drop=True)"
   ],
   "id": "93d4a7977445c251",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:08:40.261227Z",
     "start_time": "2025-08-14T03:08:40.256998Z"
    }
   },
   "cell_type": "code",
   "source": "train.head(5)",
   "id": "6806cd3dca507508",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  As an AI, I don't have personal beliefs or opi...               1   \n",
       "1  A marriage license and a marriage certificate ...               0   \n",
       "2  Function calling is the process of invoking a ...               0   \n",
       "3  When building a classifier for a very rare cat...               1   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:27:13.798624Z",
     "start_time": "2025-08-14T03:27:13.626283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train['text'] = 'User prompt: ' + train['prompt'] + '\\n\\nModel A :\\n' + train[\n",
    "    'response_a'] + '\\n\\n--------\\n\\nModel B:\\n' + train['response_b']\n",
    "print(train['text'][4])"
   ],
   "id": "4d40d17480c9be5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: What is the best way to travel from Tel-Aviv to Jerusalem? Car? Bus? Plane?\n",
      "\n",
      "Model A :\n",
      "The best way to travel from Tel Aviv to Jerusalem depends on your personal preference and the availability of transportation options. All the options you have mentioned are valid options, but here are some details to help you make your decision:\\n\\n*   By car: Traveling by car is the quickest way to get from Tel Aviv to Jerusalem, as the distance between the two cities is only about 60 kilometers (37 miles). It takes around 45 minutes to drive from Tel Aviv to Jerusalem by car, depending on the traffic.\\n*   By bus: There are several bus lines that run from Tel Aviv to Jerusalem, and the journey takes around 1 hour and 30 minutes by bus. The buses are comfortable and reliable, and they offer a scenic view of the beautiful Israeli countryside.\\n*   By plane: There are no direct flights from Tel Aviv to Jerusalem, so you need to take a flight from Tel Aviv's Ben Gurion International Airport to Jerusalem's Sde Dov Airport. The flight takes around 30 minutes, and it is a convenient option if you are short on time.\\n\\nIn general, if you have enough time and don't mind taking the bus, I recommend that option. The buses are comfortable, reliable, and offer a scenic view of the countryside. If you are short on time and don't want to take a bus, a flight is another option to consider.\n",
      "\n",
      "--------\n",
      "\n",
      "Model B:\n",
      "The best way to travel from Tel-Aviv to Jerusalem depends on your personal preferences and circumstances. \\n\\nIf you have a car and enjoy driving, then driving from Tel-Aviv to Jerusalem is an option. However, parking in Jerusalem can be challenging and expensive.\\n\\nIf you prefer to use public transportation, there are several bus lines that operate between Tel-Aviv and Jerusalem. Some of the most popular bus companies include Egged and Dan. The bus ride typically takes about an hour, depending on traffic.\\n\\nTaking a plane is not a recommended option since Tel-Aviv and Jerusalem are relatively close cities, and there are no airports in Jerusalem. \\n\\nIn summary, taking a bus is the most commonly used and convenient way to travel from Tel-Aviv to Jerusalem.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:30:08.358362Z",
     "start_time": "2025-08-14T03:29:54.860693Z"
    }
   },
   "cell_type": "code",
   "source": "train.loc[:, 'token_count'] = get_token_lengths(train['text'])",
   "id": "b04672090cce8b57",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:30:27.939105Z",
     "start_time": "2025-08-14T03:30:27.932671Z"
    }
   },
   "cell_type": "code",
   "source": "train.head(5)",
   "id": "353361050108368f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  As an AI, I don't have personal beliefs or opi...               1   \n",
       "1  A marriage license and a marriage certificate ...               0   \n",
       "2  Function calling is the process of invoking a ...               0   \n",
       "3  When building a classifier for a very rare cat...               1   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \\\n",
       "0               0           0   \n",
       "1               1           0   \n",
       "2               0           1   \n",
       "3               0           0   \n",
       "4               1           0   \n",
       "\n",
       "                                                text  token_count  \n",
       "0  User prompt: Is it morally right to try to hav...         1206  \n",
       "1  User prompt: What is the difference between ma...         1393  \n",
       "2  User prompt: explain function calling. how wou...          664  \n",
       "3  User prompt: How can I create a test set for a...         1008  \n",
       "4  User prompt: What is the best way to travel fr...          479  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: Is it morally right to try to hav...</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: What is the difference between ma...</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>User prompt: explain function calling. how wou...</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: How can I create a test set for a...</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: What is the best way to travel fr...</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:32:37.603733Z",
     "start_time": "2025-08-14T03:32:37.591590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)\n",
    "\n",
    "# Display data\n",
    "display(train.head())"
   ],
   "id": "2fffc64e5524865e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  As an AI, I don't have personal beliefs or opi...               1   \n",
       "1  A marriage license and a marriage certificate ...               0   \n",
       "2  Function calling is the process of invoking a ...               0   \n",
       "3  When building a classifier for a very rare cat...               1   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \\\n",
       "0               0           0   \n",
       "1               1           0   \n",
       "2               0           1   \n",
       "3               0           0   \n",
       "4               1           0   \n",
       "\n",
       "                                                text  token_count  label  \n",
       "0  User prompt: Is it morally right to try to hav...         1206      0  \n",
       "1  User prompt: What is the difference between ma...         1393      1  \n",
       "2  User prompt: explain function calling. how wou...          664      2  \n",
       "3  User prompt: How can I create a test set for a...         1008      0  \n",
       "4  User prompt: What is the best way to travel fr...          479      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: Is it morally right to try to hav...</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: What is the difference between ma...</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>User prompt: explain function calling. how wou...</td>\n",
       "      <td>664</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: How can I create a test set for a...</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>User prompt: What is the best way to travel fr...</td>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:34:20.121794Z",
     "start_time": "2025-08-14T03:34:20.116865Z"
    }
   },
   "cell_type": "code",
   "source": "train.label.value_counts()",
   "id": "fb2a0e86006373ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    20061\n",
       "1    19648\n",
       "2    17749\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:39:13.441084Z",
     "start_time": "2025-08-14T03:39:13.435851Z"
    }
   },
   "cell_type": "code",
   "source": "train['token_count'].describe().to_frame().astype(int)",
   "id": "937cd49e2872b211",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       token_count\n",
       "count        57458\n",
       "mean           732\n",
       "std            790\n",
       "min             17\n",
       "25%            291\n",
       "50%            566\n",
       "75%            895\n",
       "max          31035"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:40:19.628492Z",
     "start_time": "2025-08-14T03:40:19.623882Z"
    }
   },
   "cell_type": "code",
   "source": "np.percentile(train['token_count'], 90)",
   "id": "14c6bf11ecb11c14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1397.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:46:22.123389Z",
     "start_time": "2025-08-14T03:46:04.427726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = tokenizer(\n",
    "    train['text'].tolist(),\n",
    "    padding='max_length',\n",
    "    max_length=CFG.MAX_LENGTH,\n",
    "    truncation=True,\n",
    "    return_tensors='np'\n",
    ")\n",
    "\n",
    "# input IDs are the token IDs\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "# Attention masks to Ignore padding tokens\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "\n",
    "# Label of texts\n",
    "LABELS = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\n",
    "print(f'LABELS shape: {LABELS.shape}')"
   ],
   "id": "c163ba0953575d16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_IDS shape: (57458, 1024), ATTENTION_MASKS shape: (57458, 1024)\n",
      "LABELS shape: (57458, 3)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T03:54:41.019542Z",
     "start_time": "2025-08-14T03:54:41.013629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_dataset(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))\n",
    "    while True:\n",
    "        np.random.shuffle(IDXS)\n",
    "\n",
    "        for idxs in IDXS.reshape(-1, batch_size):\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(device)\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(device)\n",
    "            labels = torch.tensor(LABELS[idxs]).to(device)\n",
    "\n",
    "            yield input_ids, attention_mask, labels\n",
    "\n",
    "\n",
    "TRAIN_DATASET = train_dataset(CFG.BATCH_SIZE)"
   ],
   "id": "b5ea92ec5acf92ca",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    CFG.MODEL_NAME,\n",
    "    num_label=CFG.NUM_LABELS,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model.config.pretraining_tp = 1\n",
    "\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ],
   "id": "d842b6ae84e336e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=CFG.LORA_RANK,\n",
    "    lora_alpha=CFG.LORA_ALPHA,\n",
    "    lora_dropout=CFG.DROPOUT,\n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=CFG.LORA_MODULES\n",
    ")"
   ],
   "id": "de52440123f896ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "d98df038e252a5e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MODEL_LAYERS_ROWS = []\n",
    "TRAINABLE_PARAMS = []\n",
    "N_TRAINABLE_PARAMS = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
    "\n",
    "    if param.requires_grad:\n",
    "        MODEL_LAYERS_ROWS.append({\n",
    "            'param': n_parameters,\n",
    "            'name': name,\n",
    "            'dtype': param.data.dtype,\n",
    "        })\n",
    "\n",
    "        TRAINABLE_PARAMS.append({'param': param})\n",
    "\n",
    "        N_TRAINABLE_PARAMS += n_parameters\n",
    "display(pd.DataFrame(MODEL_LAYERS_ROWS))\n",
    "\n",
    "print(f\"\"\"\n",
    "===============================\n",
    "N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}\n",
    "N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}\n",
    "===============================\n",
    "\"\"\")"
   ],
   "id": "f6f217c0b7e87949"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "N_SAMPLES = len(train)\n",
    "STEPS_PER_EPOCH = N_SAMPLES // CFG.BATCH_SIZE\n",
    "\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=CFG.LR_MAX)\n",
    "\n",
    "# Cosine Learning Rate With Warmup\n",
    "lr_scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "    optimizer=OPTIMIZER,\n",
    "    num_warmup_steps=CFG.NUM_WARMUP_STEPS,\n",
    "    num_training_steps=STEPS_PER_EPOCH * CFG.NUM_EPOCH\n",
    ")\n",
    "print(f'BATCH_SIZE: {CFG.BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')"
   ],
   "id": "7b712a5e42403ec1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for state in OPTIMIZER.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:\n",
    "            state[k] = v.to(dtype=torch.float32)\n",
    "\n",
    "input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "\n",
    "print(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')\n",
    "print(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')\n",
    "print(f'labels shape: {labels.shape}, dtype: {labels.dtype}')"
   ],
   "id": "f62bf7d2cca5f5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "# Dummy Prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "print(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')"
   ],
   "id": "6d3c639d467b2584"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.train()\n",
    "\n",
    "# Loss function, Cross Entropy\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss().to(device=device, dtype=torch.float32)\n",
    "st = time()\n",
    "warnings.filterwarnings(\"error\")\n",
    "METRICS = {\n",
    "    \"loss\": [],\n",
    "    'accuracy': {'y_true': [], 'y_pred': []}\n",
    "}\n",
    "\n",
    "print(f'CFG.NUM_EPOCHS={CFG.NUM_EPOCH}, STEPS_PER_EPOCH={STEPS_PER_EPOCH}')\n",
    "\n",
    "for epoch in tqdm(range(CFG.NUM_EPOCH)):\n",
    "    ste = time()\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        # Zero out Gradient\n",
    "        OPTIMIZER.zero_grad()\n",
    "\n",
    "        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        logits = outputs.logits.to(dtype=torch.float32)\n",
    "\n",
    "        loss = LOSS_FN(logits, labels.to(dtype=torch.float32))\n",
    "        loss.backward()\n",
    "\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        METRICS['loss'].append(float(loss))\n",
    "        METRICS['accuracy']['y_true'] += labels.squeeze().tolist()\n",
    "        METRICS['accuracy']['y_pred'] += torch.argmax(F.softmax(logits, dim=-1), dim=-1).cpu().tolist()\n",
    "\n",
    "        if (step + 1) % 200 == 0:\n",
    "            metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
    "            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])\n",
    "            metrics += ', µ_auc: {:.3f}'.format(\n",
    "                accuracy_score(torch.argmax(torch.tensor(METRICS['accuracy']['y_true']), dim=-1),\n",
    "                               METRICS['accuracy']['y_pred']))\n",
    "            lr = OPTIMIZER.param_groups[0]['lr']\n",
    "            print(f'{epoch + 1:02}/{CFG.NUM_EPOCH:02} | {step + 1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}',\n",
    "                  end='')\n",
    "            print(f'\\nSteps per epoch: {step + 1} complete | Time elapsed: {time() - st}')\n",
    "    print(f'\\nEpoch {epoch + 1} Completed | Total time for epoch: {time() - ste} ')\n",
    "\n",
    "    torch.save(\n",
    "        {k: v.cpu() for k, v in model.named_parameters() if v.requires_grad},\n",
    "        f'model_llama_3_cp_{epoch + 1}_v1.pth'\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        OPTIMIZER.state_dict(),\n",
    "        f'optimizer_llama_3_cp_{epoch + 1}_v1.pth'\n",
    "    )\n"
   ],
   "id": "fce531dcf5f2b5fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
